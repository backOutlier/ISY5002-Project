{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:57:50.034074Z",
     "iopub.status.busy": "2024-10-17T07:57:50.033763Z",
     "iopub.status.idle": "2024-10-17T07:57:54.887767Z",
     "shell.execute_reply": "2024-10-17T07:57:54.886742Z",
     "shell.execute_reply.started": "2024-10-17T07:57:50.034039Z"
    },
    "id": "jdvoPWntkj2x"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "kaggle平台训练\n",
    "'''\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:57:54.889704Z",
     "iopub.status.busy": "2024-10-17T07:57:54.889279Z",
     "iopub.status.idle": "2024-10-17T07:57:54.893964Z",
     "shell.execute_reply": "2024-10-17T07:57:54.892886Z",
     "shell.execute_reply.started": "2024-10-17T07:57:54.889671Z"
    },
    "id": "SxPDbb64qoqc",
    "outputId": "b22b3129-a082-4f05-fbd1-ee45657348de"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !mkdir -p ~/.kaggle\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:57:54.895568Z",
     "iopub.status.busy": "2024-10-17T07:57:54.895155Z",
     "iopub.status.idle": "2024-10-17T07:57:54.910078Z",
     "shell.execute_reply": "2024-10-17T07:57:54.909150Z",
     "shell.execute_reply.started": "2024-10-17T07:57:54.895508Z"
    },
    "id": "1LwBaTbxqqMf",
    "outputId": "5cab55d8-12a5-44cc-e90b-2bdc9df4a161"
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d shubhamgoel27/dermnet\n",
    "\n",
    "# !unzip dermnet.zip -d dermnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:57:54.912668Z",
     "iopub.status.busy": "2024-10-17T07:57:54.912340Z",
     "iopub.status.idle": "2024-10-17T07:57:54.918204Z",
     "shell.execute_reply": "2024-10-17T07:57:54.917246Z",
     "shell.execute_reply.started": "2024-10-17T07:57:54.912631Z"
    },
    "id": "Mu9mYW17qr-W",
    "outputId": "05ce5bc0-666f-44a5-af8a-3b5d99612a02"
   },
   "outputs": [],
   "source": [
    "# !ls dermnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:57:54.919701Z",
     "iopub.status.busy": "2024-10-17T07:57:54.919315Z",
     "iopub.status.idle": "2024-10-17T07:57:54.925889Z",
     "shell.execute_reply": "2024-10-17T07:57:54.925026Z",
     "shell.execute_reply.started": "2024-10-17T07:57:54.919668Z"
    },
    "id": "T_TrOwmhqy-v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-17T07:57:54.928016Z",
     "iopub.status.busy": "2024-10-17T07:57:54.927619Z"
    },
    "id": "PQhlIYt7rVSt"
   },
   "outputs": [],
   "source": [
    "# @title Default title text\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "# 定义预处理步骤\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((180, 180)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((180, 180)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 定义你想要加载的类别\n",
    "selected_folders = ['Acne and Rosacea Photos',\n",
    " 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions',\n",
    " 'Atopic Dermatitis Photos',\n",
    " 'Bullous Disease Photos',\n",
    " 'Cellulitis Impetigo and other Bacterial Infections',\n",
    " 'Tinea Ringworm Candidiasis and other Fungal Infections',\n",
    "  'Melanoma Skin Cancer Nevi and Moles',\n",
    " 'Eczema Photos']  # 替换为你想加载的类别\n",
    "\n",
    "# train_data_dir = '/content/dermnet/train'\n",
    "# test_data_dir = '/content/dermnet/test'\n",
    "train_data_dir = '/input/dermnet/train'\n",
    "test_data_dir = '/input/dermnet/test'\n",
    "\n",
    "# 加载完整的训练数据和测试数据\n",
    "df_train_full = datasets.ImageFolder(root=train_data_dir, transform=transform_train)\n",
    "df_test_full = datasets.ImageFolder(root=test_data_dir, transform=transform_test)\n",
    "\n",
    "# 获取类别名与索引的映射\n",
    "# Original: class_to_idx = {v: k for k, v in df_train_full.class_to_idx.items()}  # 反转字典\n",
    "# Changed: Using the original class_to_idx where keys are class names and values are indices\n",
    "class_to_idx = df_train_full.class_to_idx\n",
    "\n",
    "# 找出选定类别对应的索引\n",
    "# Original: selected_idx = [class_to_idx[folder] for folder in selected_folders]\n",
    "# Changed: Accessing the index using the class name as the key\n",
    "selected_idx = [class_to_idx[folder] for folder in selected_folders if folder in class_to_idx]\n",
    "\n",
    "# 过滤出选定类别的数据索引\n",
    "train_indices = [i for i, (_, label) in enumerate(df_train_full) if label in selected_idx]\n",
    "test_indices = [i for i, (_, label) in enumerate(df_test_full) if label in selected_idx]\n",
    "\n",
    "# 使用 Subset 只加载指定类别的数据\n",
    "df_train_subset = Subset(df_train_full, train_indices)\n",
    "df_test_subset = Subset(df_test_full, test_indices)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64\n",
    "train_data_loader = DataLoader(df_train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(df_test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 查看加载数据的类别\n",
    "class_names = [folder for folder in df_train_full.classes if folder in selected_folders]\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_CMGGUPyXFA",
    "outputId": "348509ad-a555-408d-92b4-14263956e01e"
   },
   "outputs": [],
   "source": [
    "# @title Default title text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# train_data_dir = '/content/dermnet/train'\n",
    "# test_data_dir = '/content/dermnet/test'\n",
    "train_data_dir = '/input/dermnet/train'\n",
    "test_data_dir = '/input/dermnet/test'\n",
    "df_train = datasets.ImageFolder(root=train_data_dir, transform=transform_train)\n",
    "df_test = datasets.ImageFolder(root=test_data_dir,transform=transform_test)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64\n",
    "train_data_loader = DataLoader(df_train, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(df_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# show a batch data\n",
    "images, labels = next(iter(train_data_loader))\n",
    "print(f'Image batch shape: {images.shape}')\n",
    "print(f'Label batch shape: {labels.shape}')\n",
    "\n",
    "class_names = df_train.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QT-4pA_WsVFA",
    "outputId": "c06b0ea2-a4d1-4ddb-9c93-0862c9b5fd40"
   },
   "outputs": [],
   "source": [
    "test_data_loader\n",
    "train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcMzTj6pzYn1",
    "outputId": "83bc799d-4033-4eaf-a5c4-adf8276ce2ca"
   },
   "outputs": [],
   "source": [
    "# @title Default title text\n",
    "!pip install torch torchvision\n",
    "!pip install efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8OKzZJ0zySP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5i-j_-cwv7mz"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdsZpy_KyhfX",
    "outputId": "afe5b49d-fc36-41f4-e02f-c3bae5f62fcf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要改动换掉这个类，其余的正常运行就好\n",
    "class CustomDenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomDenseNet121, self).__init__()\n",
    "        # load DenseNet121\n",
    "        self.base_model = models.densenet121(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Remove the classification layer\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "num_classes = 23\n",
    "model = CustomDenseNet121(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EVyBG0kzpCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JITg75juy78k"
   },
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWIy10bdK2hF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义早停法参数  \n",
    "early_stopping_patience = 10  \n",
    "early_stopping_counter = 0  \n",
    "best_val_loss = float('inf')  \n",
    "stop_training = False  # 手动停止训练的标志  \n",
    "  \n",
    "# 定义ReduceLROnPlateau调度器  \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)  \n",
    "  \n",
    "num_epochs = 70  \n",
    "train_losses = []  \n",
    "train_accuracies = []  \n",
    "val_losses = []  \n",
    "val_accuracies = []  \n",
    "  \n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))  \n",
    "loss_line1, = axs[0].plot([], [], label='Train Loss')  \n",
    "loss_line2, = axs[0].plot([], [], label='Validation Loss')  \n",
    "acc_line1, = axs[1].plot([], [], label='Train Accuracy')  \n",
    "acc_line2, = axs[1].plot([], [], label='Validation Accuracy')  \n",
    "  \n",
    "def init():  \n",
    "    for line in [loss_line1, loss_line2, acc_line1, acc_line2]:  \n",
    "        line.set_data([], [])  \n",
    "    return loss_line1, loss_line2, acc_line1, acc_line2  \n",
    "  \n",
    "def update(epoch):  \n",
    "    axs[0].set_xlim(0, num_epochs)  \n",
    "    axs[0].set_ylim(0, max(max(train_losses), max(val_losses)) * 1.1 if train_losses and val_losses else 1)  \n",
    "    axs[1].set_ylim(0, 100)  \n",
    "      \n",
    "    loss_line1.set_data(range(1, epoch + 1), train_losses)  \n",
    "    loss_line2.set_data(range(1, epoch + 1), val_losses)  \n",
    "    acc_line1.set_data(range(1, epoch + 1), train_accuracies)  \n",
    "    acc_line2.set_data(range(1, epoch + 1), val_accuracies)  \n",
    "      \n",
    "    return loss_line1, loss_line2, acc_line1, acc_line2  \n",
    "  \n",
    "# ani = animation.FuncAnimation(fig, update, frames=num_epochs, init_func=init, blit=True, interval=1000)  # interval以毫秒为单位  \n",
    "# plt.show(block=False)  # 非阻塞模式显示动画  \n",
    "  \n",
    "for epoch in range(num_epochs): \n",
    "    # 训练代码\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            batch_loss = running_loss / (i + 1)\n",
    "            batch_accuracy = 100 * correct / total\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_data_loader)}], '\n",
    "                  f'Train Loss: {batch_loss:.4f}, Train Accuracy: {batch_accuracy:.2f}%')\n",
    "        \n",
    "    avg_loss = running_loss / len(train_data_loader)\n",
    "    avg_accuracy = 100 * correct / total\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(avg_accuracy)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] completed. Average Train Loss: {avg_loss:.4f}, '\n",
    "          f'Average Train Accuracy: {avg_accuracy:.2f}%')\n",
    "    # 验证代码  \n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_running_loss / len(test_data_loader)\n",
    "    avg_val_accuracy = 100 * val_correct / val_total\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(avg_val_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] completed. Validation Loss: {avg_val_loss:.4f}, '\n",
    "          f'Validation Accuracy: {avg_val_accuracy:.2f}%')  \n",
    "    # 更新学习率调度器  \n",
    "    scheduler.step(avg_val_loss)  \n",
    "      \n",
    "    # 早停法逻辑  \n",
    "    if avg_val_loss < best_val_loss:  \n",
    "        best_val_loss = avg_val_loss  \n",
    "        early_stopping_counter = 0  \n",
    "    else:  \n",
    "        early_stopping_counter += 1  \n",
    "      \n",
    "    # 检查是否应该停止训练  \n",
    "    if early_stopping_counter >= early_stopping_patience or stop_training:  \n",
    "        print(f'Early stopping at epoch {epoch + 1} due to no improvement in validation loss.')  \n",
    "        break  \n",
    "      \n",
    "# 训练结束后保存曲线图 \n",
    "plt.figure(figsize=(12, 5))  \n",
    "plt.subplot(1, 2, 1)  \n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')  \n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('Training and Validation Loss')  \n",
    "plt.legend()  \n",
    "  \n",
    "plt.subplot(1, 2, 2)  \n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')  \n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylabel('Accuracy (%)')  \n",
    "plt.title('Training and Validation Accuracy')  \n",
    "plt.legend()  \n",
    "  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('training_curves.png')  # 保存曲线图  \n",
    "plt.show()  # 在本地显示曲线图（Kaggle等在线环境可能不支持显示）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NF-6zjjzzSFG",
    "outputId": "02b68082-3048-478f-a85b-a9afbfc51eab"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # define ReduceLROnPlateau schedule\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# num_epochs = 70\n",
    "# train_losses = []\n",
    "# train_accuracies = []\n",
    "# val_losses = []\n",
    "# val_accuracies = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for i, (images, labels) in enumerate(train_data_loader):\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#         if (i + 1) % 5 == 0:\n",
    "#             batch_loss = running_loss / (i + 1)\n",
    "#             batch_accuracy = 100 * correct / total\n",
    "#             print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_data_loader)}], '\n",
    "#                   f'Train Loss: {batch_loss:.4f}, Train Accuracy: {batch_accuracy:.2f}%')\n",
    "\n",
    "#     avg_loss = running_loss / len(train_data_loader)\n",
    "#     avg_accuracy = 100 * correct / total\n",
    "#     train_losses.append(avg_loss)\n",
    "#     train_accuracies.append(avg_accuracy)\n",
    "#     print(f'Epoch [{epoch + 1}/{num_epochs}] completed. Average Train Loss: {avg_loss:.4f}, '\n",
    "#           f'Average Train Accuracy: {avg_accuracy:.2f}%')\n",
    "\n",
    "#     # validation\n",
    "#     model.eval()\n",
    "#     val_running_loss = 0.0\n",
    "#     val_correct = 0\n",
    "#     val_total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in test_data_loader:\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             val_running_loss += loss.item()\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             val_total += labels.size(0)\n",
    "#             val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     avg_val_loss = val_running_loss / len(test_data_loader)\n",
    "#     avg_val_accuracy = 100 * val_correct / val_total\n",
    "#     val_losses.append(avg_val_loss)\n",
    "#     val_accuracies.append(avg_val_accuracy)\n",
    "\n",
    "#     print(f'Epoch [{epoch + 1}/{num_epochs}] completed. Validation Loss: {avg_val_loss:.4f}, '\n",
    "#           f'Validation Accuracy: {avg_val_accuracy:.2f}%')\n",
    "\n",
    "#     # ReduceLROnPlateau learning rate\n",
    "#     scheduler.step(avg_val_loss)\n",
    "\n",
    "# # loss diagram\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "# plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# # accuracy diagram\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "# plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqBMWWT8zBWw"
   },
   "outputs": [],
   "source": [
    "# save\n",
    "# torch.save(model.state_dict(), 'resnet50_skin_disease_model.pth')\n",
    "# torch.save(model, 'vgg16_skin_disease_model.pth')\n",
    "torch.save(model, 'DenseNet121_skin_disease_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDwVxgppQl7y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHnfUA51Lb2L",
    "outputId": "5f32a40f-5746-48bb-e6b5-38c930db1d0e"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# classifier report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# The confusion matrix heat map\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZjfBwx38P09"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 735911,
     "sourceId": 1276317,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5884518,
     "sourceId": 9637535,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 96990114,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
